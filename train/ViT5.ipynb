{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"zOmMYTF8gvOr"},"outputs":[],"source":["!pip install transformers datasets torch scikit-learn evaluate rouge_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9wBlLwlCygXx"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2zNMpIbhg7IP"},"outputs":[],"source":["import pandas as pd\n","from transformers import T5Tokenizer\n","from datasets import Dataset\n","\n","# Đọc dữ liệu từ các file CSV\n","train_data = pd.read_csv(\"/content/drive/MyDrive/NLP/dataset/new/train.csv\")\n","val_data = pd.read_csv(\"/content/drive/MyDrive/NLP/dataset/new/val.csv\")\n","test_data = pd.read_csv(\"/content/drive/MyDrive/NLP/dataset/new/test.csv\")\n","\n","# Đảm bảo các file có cột `input_text` và `summary_text`\n","def preprocess_data(data):\n","    return [{\"input_text\": row[\"Content\"], \"summary_text\": row[\"Summarize\"]} for _, row in data.iterrows()]\n","\n","train_dataset = preprocess_data(train_data)\n","val_dataset = preprocess_data(val_data)\n","test_dataset = preprocess_data(test_data)\n","\n","train_dataset = Dataset.from_pandas(pd.DataFrame(train_dataset))\n","val_dataset = Dataset.from_pandas(pd.DataFrame(val_dataset))\n","test_dataset = Dataset.from_pandas(pd.DataFrame(test_dataset))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P4gyTipFikuP"},"outputs":[],"source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"VietAI/vit5-base\")\n","\n","# Hàm tiền xử lý dữ liệu\n","def preprocess_function(examples):\n","    inputs = [\"summarize: \" + example[\"input_text\"] for example in examples]\n","    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n","    # Tokenize phần tóm tắt (summary)\n","    labels = tokenizer([example[\"summary_text\"] for example in examples], max_length=128, truncation=True, padding=\"max_length\")\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs\n","\n","# Áp dụng tiền xử lý\n","train_encodings = preprocess_function(train_dataset)\n","val_encodings = preprocess_function(val_dataset)\n","test_encodings = preprocess_function(test_dataset)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S_UEsQtgi2dT"},"outputs":[],"source":["import torch\n","\n","class TextSummaryDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings):\n","        self.encodings = encodings\n","\n","    def __len__(self):\n","        return len(self.encodings[\"input_ids\"])\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        return item\n","\n","train_dataset = TextSummaryDataset(train_encodings)\n","val_dataset = TextSummaryDataset(val_encodings)\n","test_dataset = TextSummaryDataset(test_encodings)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e1UxloNWjKHx"},"outputs":[],"source":["from transformers import T5ForConditionalGeneration, Trainer, TrainingArguments, AutoTokenizer\n","\n","# Load model và tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"VietAI/vit5-base\")\n","model = T5ForConditionalGeneration.from_pretrained(\"VietAI/vit5-base\")\n","\n","# Định nghĩa các tham số huấn luyện\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",                # Thư mục lưu kết quả và checkpoint\n","    evaluation_strategy=\"epoch\",          # Đánh giá sau mỗi epoch\n","    learning_rate=5e-5,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=8,\n","    weight_decay=0.01,\n","    save_strategy=\"steps\",                # Lưu checkpoint sau mỗi số bước\n","    save_steps=500,                       # Lưu checkpoint mỗi 500 bước\n","    save_total_limit=3,                   # Chỉ giữ lại 3 checkpoint gần nhất\n","    fp16=True,                            # Sử dụng mixed precision (nếu GPU hỗ trợ)\n","    logging_dir='./logs',                 # Thư mục lưu log\n","    logging_steps=10,\n","    report_to=\"none\",                     # Không đẩy logs lên hệ thống bên ngoài\n","    push_to_hub=False,\n",")\n","\n","# Khởi tạo Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    tokenizer=tokenizer,\n",")\n","\n","# Huấn luyện\n","trainer.train()\n","\n","# Tiếp tục từ checkpoint nếu cần\n","# trainer.train(resume_from_checkpoint=\"./results/checkpoint-500\")\n","save_path = \"/content/drive/MyDrive/NLP/models/vit5-finetuned-pmc\"\n","\n","# Lưu mô hình đã huấn luyện\n","model.save_pretrained(save_path)\n","tokenizer.save_pretrained(save_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jj6Fro9AwkXt"},"outputs":[],"source":["from transformers import T5Tokenizer, T5ForConditionalGeneration\n","\n","# Load the fine-tuned model and tokenizer\n","model_path = \"/content/drive/MyDrive/NLP/models/vit5-finetuned\"\n","tokenizer = T5Tokenizer.from_pretrained(model_path)\n","model = T5ForConditionalGeneration.from_pretrained(model_path)\n","\n","# Function to generate predictions\n","def generate_summary(input_text, max_length=128):\n","    # Preprocess the input\n","    input_ids = tokenizer(\n","        \"summarize: \" + input_text,\n","        return_tensors=\"pt\",\n","        max_length=512,\n","        truncation=True,\n","    ).input_ids\n","\n","    # Generate the summary\n","    output_ids = model.generate(input_ids, max_length=max_length, num_beams=4, early_stopping=True)\n","    summary = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n","    return summary\n","\n","# Test the model on your test dataset\n","test_results = []\n","for example in test_dataset:  # Assuming `test_dataset` is in PyTorch Dataset format\n","    input_text = tokenizer.decode(example[\"input_ids\"], skip_special_tokens=True)\n","    true_summary = tokenizer.decode(example[\"labels\"], skip_special_tokens=True)\n","    generated_summary = generate_summary(input_text)\n","\n","    test_results.append({\n","        \"Input\": input_text,\n","        \"True Summary\": true_summary,\n","        \"Generated Summary\": generated_summary\n","    })\n","\n","# Print results for evaluation\n","for result in test_results[:2]:  # Print first 10 examples\n","    print(f\"Input: {result['Input']}\")\n","    print(f\"True Summary: {result['True Summary']}\")\n","    print(f\"Generated Summary: {result['Generated Summary']}\")\n","    print(\"=\" * 80)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tt1tgmHSyVJz"},"outputs":[],"source":["import evaluate\n","\n","rouge = evaluate.load(\"rouge\")\n","\n","# Compute ROUGE scores for generated and true summaries\n","generated_summaries = [result[\"Generated Summary\"] for result in test_results]\n","true_summaries = [result[\"True Summary\"] for result in test_results]\n","\n","rouge_score = rouge.compute(predictions=generated_summaries, references=true_summaries)\n","print(rouge_score)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[{"file_id":"1Bn82c9b4vS5PjUO2o2cyGTL3hsXAYcFY","timestamp":1735997844971}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}